{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "0460ed49-e72c-4d1a-bde0-bf2ae1e57025",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fugashi                        1.1.0\n",
      "ipadic                         1.0.0\n",
      "tensorflow                     2.4.1\n",
      "tensorflow-addons              0.12.1\n",
      "tensorflow-cloud               0.1.13\n",
      "tensorflow-data-validation     0.29.0\n",
      "tensorflow-datasets            3.0.0\n",
      "tensorflow-estimator           2.4.0\n",
      "tensorflow-gpu                 2.4.1\n",
      "tensorflow-hub                 0.9.0\n",
      "tensorflow-metadata            0.29.0\n",
      "tensorflow-model-analysis      0.29.0\n",
      "tensorflow-serving-api         2.4.1\n",
      "tensorflow-transform           0.29.0\n",
      "transformers                   4.8.1\n"
     ]
    }
   ],
   "source": [
    "# !pip install transformers fugashi[unidic-lite] ipadic\n",
    "!pip list | grep 'transformers\\|fugashi\\|ipadic\\|tensorflow'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "984a8b54-3eda-4b72-b926-baeb4613c931",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "checkpoint = \"cl-tohoku/bert-base-japanese-whole-word-masking\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "9b8dc7da-d377-45d7-b7a9-b88285e42370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': <tf.Tensor: shape=(1, 10), dtype=int32, numpy=\n",
      "array([[   2,  571,   12,    4,    5,  608,   11, 2867,    8,    3]],\n",
      "      dtype=int32)>, 'token_type_ids': <tf.Tensor: shape=(1, 10), dtype=int32, numpy=array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=int32)>, 'attention_mask': <tf.Tensor: shape=(1, 10), dtype=int32, numpy=array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], dtype=int32)>}\n"
     ]
    }
   ],
   "source": [
    "raw_inputs = [\n",
    "    #'テレビでサッカーの試合を見る。', \n",
    "    'テレビで' + tokenizer.mask_token + 'の試合を見る。', \n",
    "]\n",
    "inputs = tokenizer(raw_inputs, padding=True, truncation=True, return_tensors=\"tf\")\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "21c76bca-a16b-48c1-8a62-5f7b1d502ff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForMaskedLM.\n",
      "\n",
      "All the layers of TFBertForMaskedLM were initialized from the model checkpoint at cl-tohoku/bert-base-japanese-whole-word-masking.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForMaskedLM for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 10, 32000)\n"
     ]
    }
   ],
   "source": [
    "from transformers import TFAutoModelForMaskedLM\n",
    "\n",
    "model = TFAutoModelForMaskedLM.from_pretrained(checkpoint)\n",
    "outputs = model(inputs)\n",
    "print(outputs.logits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "ad66417c-f37d-4771-bef5-38311dbcc600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[3.7459305e-08 1.0108354e-03 3.0044521e-07 ... 9.5772705e-08\n",
      "   1.4990446e-08 1.3698190e-07]\n",
      "  [2.2006600e-13 5.4908986e-07 3.1778032e-11 ... 6.3342663e-13\n",
      "   2.9647142e-13 1.1226209e-12]\n",
      "  [1.6911761e-15 4.8180787e-08 1.7189679e-12 ... 1.9864927e-14\n",
      "   4.0749305e-14 4.7688399e-14]\n",
      "  ...\n",
      "  [3.1071811e-13 1.9899795e-07 2.3371231e-12 ... 3.6241833e-14\n",
      "   6.2069416e-12 2.8103923e-14]\n",
      "  [1.0250574e-12 2.7231323e-07 6.7588213e-10 ... 3.3563010e-11\n",
      "   5.8855171e-11 1.3667138e-12]\n",
      "  [3.8539120e-12 5.3201114e-07 7.5232398e-10 ... 1.7161642e-10\n",
      "   6.5043609e-12 1.3238502e-12]]], shape=(1, 10, 32000), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "predictions = tf.math.softmax(outputs.logits, axis=-1)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "2049da85-baaa-4298-8326-7fd4b506d393",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1301,  5653, 15235], dtype=int32)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = tf.math.top_k(tf.math.softmax(outputs.logits[0, 3, :], axis=-1), k=3)  # get top 3 candidates\n",
    "results.indices.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "e704cd54-1d6b-4f28-89af-af858e49eb41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 サッカー\n",
      "1 バスケットボール\n",
      "2 阪神タイガース\n"
     ]
    }
   ],
   "source": [
    "# Show results\n",
    "for i, index in enumerate(results.indices):\n",
    "    token = tokenizer.convert_ids_to_tokens([index])[0]\n",
    "    print(i, token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1e682fa7-7d59-48ec-8a8b-110ec83359e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForMaskedLM.\n",
      "\n",
      "All the layers of TFBertForMaskedLM were initialized from the model checkpoint at cl-tohoku/bert-base-japanese-whole-word-masking.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForMaskedLM for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "unmasker = pipeline(\"fill-mask\", model=\"cl-tohoku/bert-base-japanese-whole-word-masking\", tokenizer='cl-tohoku/bert-base-japanese-whole-word-masking')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0191acf7-44cc-4f53-89f1-1f18cb800836",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'sequence': 'テレビ で サッカー の 試合 を 見る 。',\n",
       "  'score': 0.08827631920576096,\n",
       "  'token': 1301,\n",
       "  'token_str': 'サ ッ カ ー'},\n",
       " {'sequence': 'テレビ で バスケットボール の 試合 を 見る 。',\n",
       "  'score': 0.057113878428936005,\n",
       "  'token': 5653,\n",
       "  'token_str': 'バ ス ケ ッ ト ボ ー ル'},\n",
       " {'sequence': 'テレビ で 阪神タイガース の 試合 を 見る 。',\n",
       "  'score': 0.04361201822757721,\n",
       "  'token': 15235,\n",
       "  'token_str': '阪 神 タ イ ガ ー ス'}]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unmasker(\"テレビで\" + unmasker.tokenizer.mask_token + \"の試合を見る。\", top_k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e89251dc-7651-4aaf-8111-22f715c4e112",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0362ffa3a4544988baf349200416f14e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/629 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02cee82688914baa9092730049d91d1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFDistilBertForSequenceClassification.\n",
      "\n",
      "All the layers of TFDistilBertForSequenceClassification were initialized from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f3d508de9604e0b830ce49dbc00763f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec0f24268c904609a33c9c880487ce51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9598047137260437}]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"sentiment-analysis\")\n",
    "classifier(\"I've been waiting for a HuggingFace course my whole life.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb35ccae-252c-481e-a40c-649a29eb76bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9598047137260437},\n",
       " {'label': 'NEGATIVE', 'score': 0.9994558095932007}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier([\n",
    "    \"I've been waiting for a HuggingFace course my whole life.\", \n",
    "    \"I hate this so much!\"\n",
    "])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kYC6J-E6cjQV"
   },
   "source": [
    "## Qiita記事：【実装解説】日本語版BERTをGoogle Colaboratoryで使う方法の実装コード\n",
    "\n",
    "URL：\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nOAjVollcR4z"
   },
   "source": [
    "## 準備1：MeCabをGoogle Colaboratoryにインストール"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n9TejYvKcVBK",
    "outputId": "5d04dc65-4a40-44bf-afde-41fa2e1d4b52",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !apt install aptitude swig\n",
    "# !aptitude install mecab libmecab-dev mecab-ipadic-utf8 git make curl xz-utils file -y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5anbSNgUcXPw",
    "outputId": "6a18004a-78b8-4df8-b233-6f125b2b1201"
   },
   "outputs": [],
   "source": [
    "# !pip install mecab-python3==0.996.6rc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_pQ5MY_Jcpu0",
    "outputId": "e2f35d88-7835-438c-ce1d-69af3a322239"
   },
   "outputs": [],
   "source": [
    "# need to run as root or sudo without password\n",
    "# !git clone --depth 1 https://github.com/neologd/mecab-ipadic-neologd.git\n",
    "# !echo yes | mecab-ipadic-neologd/bin/install-mecab-ipadic-neologd -n -a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "80SqXmdfc3hO"
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "cmd='echo `mecab-config --dicdir`\"/mecab-ipadic-neologd\"'\n",
    "path_neologd = (subprocess.Popen(cmd, stdout=subprocess.PIPE,\n",
    "                           shell=True).communicate()[0]).decode('utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JOTmm1u_c7qE"
   },
   "source": [
    "## 準備2：MeCabの動作確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xo5kFZUhegX9",
    "outputId": "9853ec07-4064-44f8-b1cd-3ed7157dd6fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "私\tワタシ\t私\t名詞-代名詞-一般\t\t\n",
      "は\tハ\tは\t助詞-係助詞\t\t\n",
      "機械\tキカイ\t機械\t名詞-一般\t\t\n",
      "学習\tガクシュウ\t学習\t名詞-サ変接続\t\t\n",
      "が\tガ\tが\t助詞-格助詞-一般\t\t\n",
      "好き\tスキ\t好き\t名詞-形容動詞語幹\t\t\n",
      "です\tデス\tです\t助動詞\t特殊・デス\t基本形\n",
      "。\t。\t。\t記号-句点\t\t\n",
      "EOS\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import MeCab\n",
    "\n",
    "m=MeCab.Tagger(\"-Ochasen\")\n",
    "\n",
    "text = \"私は機械学習が好きです。\"\n",
    "\n",
    "text_segmented = m.parse(text)\n",
    "print(text_segmented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "46pmM04neg5F",
    "outputId": "156a24ef-1e41-4be0-b527-7e481cde5b2b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "私 は 機械 学習 が 好き です 。 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "m=MeCab.Tagger(\"-Owakati\")\n",
    "text_segmented = m.parse(text)\n",
    "print(text_segmented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pqrfZ5w2fEIb",
    "outputId": "4093e245-f6d7-4e88-e150-8ad72a984a43"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ワタシハキカイガクシュウガスキデス。\n",
      "\n"
     ]
    }
   ],
   "source": [
    "m=MeCab.Tagger(\"-Oyomi\")\n",
    "text_segmented = m.parse(text)\n",
    "print(text_segmented)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y6pbeCbRgI8L"
   },
   "source": [
    "### 新語辞書の場合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pHuCvyP1gFOp",
    "outputId": "99d07e49-afed-4b56-a15a-13923f070736"
   },
   "outputs": [],
   "source": [
    "m=MeCab.Tagger(\"-Ochasen -d \"+str(path_neologd)  # NEologdへのパスを追加\n",
    "text = \"私は機械学習が好きです。\"\n",
    "\n",
    "text_segmented = m.parse(text)\n",
    "print(text_segmented)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "私\tワタシ\t私\t名詞-代名詞-一般\t\t\n",
      "は\tハ\tは\t助詞-係助詞\t\t\n",
      "機械学習\tキカイガクシュウ\t機械学習\t名詞-固有名詞-一般\t\t\n",
      "が\tガ\tが\t助詞-格助詞-一般\t\t\n",
      "好き\tスキ\t好き\t名詞-形容動詞語幹\t\t\n",
      "です\tデス\tです\t助動詞\t特殊・デス\t基本形\n",
      "。\t。\t。\t記号-句点\t\t\n",
      "EOS\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F04QpCE2gLy-",
    "outputId": "83a69433-3d12-471f-b991-a00884911906"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "私 は 機械学習 が 好き です 。 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "m=MeCab.Tagger(\"-Owakati -d \"+str(path_neologd))  # NEologdへのパスを追加\n",
    "text_segmented = m.parse(text)\n",
    "print(text_segmented)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QMQ46P0mlyjC"
   },
   "source": [
    "## 準備3：日本語版BERTの学習済みモデルと形態素解析を用意"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P5_fTFX9gO6D",
    "outputId": "7c63cd9d-b956-421f-ccc9-69331d093033"
   },
   "outputs": [],
   "source": [
    "#!pip install transformers==3.0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export PATH=/home/vjai/.local/bin:$PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "0PHUrr-DmIdX"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "# from transformers.modeling_bert import BertModel\n",
    "# from transformers.tokenization_bert_japanese import BertJapaneseTokenizer\n",
    "from transformers import BertJapaneseTokenizer\n",
    "from transformers import BertModel #BertForMaskedLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66,
     "referenced_widgets": [
      "c91d8155da844dfea92cbbe827bb571e",
      "e679bdf2ab794e4480faf1ce0a43adb3",
      "f76f6442d57c4554aeae1f68f74584ed",
      "349cd9965e51442abd0061ce5834df50",
      "fc88707390414c518d2c696881c58c4e",
      "1ed1a87028d9496b9ec0757f29ebef1c",
      "17b26bb56edb45b184cb175fcc780cc6",
      "5cde709e5cd1408386a9a2ee1c81e5fd"
     ]
    },
    "id": "XuwcEk47n3U0",
    "outputId": "ca879c54-6e47-4b7d-dc40-b4cced3cf9f5"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80acb35dd743411a9bc770708a9d2efd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/258k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37894c08a57f45ed96b46378dcb180e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/110 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 分かち書きをするtokenizerです\n",
    "tokenizer = BertJapaneseTokenizer.from_pretrained('cl-tohoku/bert-base-japanese-whole-word-masking')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "830efe85aec84c1bba49f3c8a9cb3a75",
      "2b64036b93dc4df2b35940e2f74d6188",
      "c854a012b2444d1581d50e5256069f53",
      "06d8c6bbd43b430299f975aaa349f9d8",
      "4fcc5b8696cc482e88b3dfe07b6a74ae",
      "a9b48b9b6a7942618a5a840826f5fd3f",
      "acebce3c8e504744bca5165eff7fe88f",
      "2833d30551d449d99cad8b9f5091d2cd",
      "70064d5eec9f45fa83a66b0595439df0",
      "54845b9127b646509f3d551659260f43",
      "c206ee4e86c6473b8d04a9f2f4525077",
      "d9f1f583bd9d46b4b7e2772e28f4a641",
      "9797141215bb406aaad08f45a25d2343",
      "3ec4fcbf79ee4f5d8a5311a58bd4dcd9",
      "061d8c2941cd4ba5b46acafa32d6197d",
      "332df7bab117491aa078b91b72fde1fe"
     ]
    },
    "id": "Y-Djqpnjn-g6",
    "outputId": "9f019d3e-6240-4368-9be0-91ca73d3b414"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f93a74551b4c4901bdc9d682b1116e80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/479 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae2cad25899449a4bf14a51e7a068362",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/445M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertModel(\n",
      "  (embeddings): BertEmbeddings(\n",
      "    (word_embeddings): Embedding(32000, 768, padding_idx=0)\n",
      "    (position_embeddings): Embedding(512, 768)\n",
      "    (token_type_embeddings): Embedding(2, 768)\n",
      "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (encoder): BertEncoder(\n",
      "    (layer): ModuleList(\n",
      "      (0): BertLayer(\n",
      "        (attention): BertAttention(\n",
      "          (self): BertSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (1): BertLayer(\n",
      "        (attention): BertAttention(\n",
      "          (self): BertSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (2): BertLayer(\n",
      "        (attention): BertAttention(\n",
      "          (self): BertSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (3): BertLayer(\n",
      "        (attention): BertAttention(\n",
      "          (self): BertSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (4): BertLayer(\n",
      "        (attention): BertAttention(\n",
      "          (self): BertSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (5): BertLayer(\n",
      "        (attention): BertAttention(\n",
      "          (self): BertSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (6): BertLayer(\n",
      "        (attention): BertAttention(\n",
      "          (self): BertSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (7): BertLayer(\n",
      "        (attention): BertAttention(\n",
      "          (self): BertSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (8): BertLayer(\n",
      "        (attention): BertAttention(\n",
      "          (self): BertSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (9): BertLayer(\n",
      "        (attention): BertAttention(\n",
      "          (self): BertSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (10): BertLayer(\n",
      "        (attention): BertAttention(\n",
      "          (self): BertSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (11): BertLayer(\n",
      "        (attention): BertAttention(\n",
      "          (self): BertSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (pooler): BertPooler(\n",
      "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (activation): Tanh()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# BERTの日本語学習済みパラメータのモデルです\n",
    "model = BertModel.from_pretrained('cl-tohoku/bert-base-japanese-whole-word-masking')\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9COwchQZoF0y",
    "outputId": "b0ecd036-f0d3-4677-a4ab-6910174ea5a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"tokenizer_class\": \"BertJapaneseTokenizer\",\n",
      "  \"transformers_version\": \"4.5.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertConfig\n",
    "\n",
    "# 東北大学_日本語版の設定を確認\n",
    "config_japanese = BertConfig.from_pretrained('cl-tohoku/bert-base-japanese-whole-word-masking')\n",
    "print(config_japanese)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3MrPVPzTr_AM"
   },
   "source": [
    "設定を見ると、単語ベクトルは768次元、最大の単語数（サブワード数）は512、BERTのレイヤー数は12層、ボキャブラリのサイズは32,000であることが分かります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YjGRSQwEzj8K"
   },
   "source": [
    "## 日本語版BERTで文章を扱う"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "LxEbvY5jzk4R"
   },
   "outputs": [],
   "source": [
    "text1 = \"会社をクビになった。\"\n",
    "text2 = \"テレワークばかりでクビが痛い。\"\n",
    "text3 = \"会社を解雇された。\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QJLVJIJZ0t-1",
    "outputId": "7fbbf703-3313-408e-b64e-4aaa0d7b84ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', '会社', 'を', 'クビ', 'に', 'なっ', 'た', '。', '[SEP]']\n",
      "tensor([[    2,   811,    11, 13700,     7,    58,    10,     8,     3]])\n"
     ]
    }
   ],
   "source": [
    "# 分かち書きをして、idに変換\n",
    "input_ids1 = tokenizer.encode(text1, return_tensors='pt')  # ptはPyTorchの略\n",
    "\n",
    "print(tokenizer.convert_ids_to_tokens(input_ids1[0].tolist()))  # 文章\n",
    "print(input_ids1)  # id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RkxX9n4k1yjk",
    "outputId": "a98d4d81-a43b-48f2-9add-a8d6e0f3243b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'テレ', '##ワーク', 'ばかり', 'で', 'クビ', 'が', '痛', '##い', '。', '[SEP]']\n",
      "tensor([[    2,  5521,  3118,  4027,    12, 13700,    14,  4897, 28457,     8,\n",
      "             3]])\n"
     ]
    }
   ],
   "source": [
    "# 分かち書きをして、idに変換\n",
    "input_ids2 = tokenizer.encode(text2, return_tensors='pt')  # ptはPyTorchの略\n",
    "\n",
    "print(tokenizer.convert_ids_to_tokens(input_ids2[0].tolist()))  # 文章\n",
    "print(input_ids2)  # id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2voPx2yE03nj",
    "outputId": "16f518ef-d188-44ce-ca3e-eae7c677a513"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', '会社', 'を', '解雇', 'さ', 'れ', 'た', '。', '[SEP]']\n",
      "tensor([[   2,  811,   11, 7279,   26,   20,   10,    8,    3]])\n"
     ]
    }
   ],
   "source": [
    "# 分かち書きをして、idに変換\n",
    "input_ids3 = tokenizer.encode(text3, return_tensors='pt')  # ptはPyTorchの略\n",
    "\n",
    "print(tokenizer.convert_ids_to_tokens(input_ids3[0].tolist()))  # 文章\n",
    "print(input_ids3)  # id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zvj4O1b516u7",
    "outputId": "44cca1cb-5129-4d83-f164-19a77bc61649"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 9, 768])\n",
      "torch.Size([1, 768])\n"
     ]
    }
   ],
   "source": [
    "# 日本語BERTモデルに入力\n",
    "result1 = model(input_ids1)\n",
    "\n",
    "print(result1[0].shape)\n",
    "print(result1[1].shape)\n",
    "\n",
    "# reult は、sequence_output, pooled_output, (hidden_states), (attentions)です。\n",
    "# ただし、hidden_statesとattentionsはoptionalであり、標準では出力されません。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "bTuqqREy3JJg"
   },
   "outputs": [],
   "source": [
    "# 日本語BERTモデルに入力\n",
    "result2 = model(input_ids2)\n",
    "result3 = model(input_ids3)\n",
    "\n",
    "word_vec1 = result1[0][0][3][:]  # 1つ目の文章の”クビ”（3番目）\n",
    "word_vec2 = result2[0][0][5][:]  # 2つ目の文章の”クビ”（5番目）\n",
    "word_vec3 = result3[0][0][3][:]  # 3つ目の文章の”解雇”（3番目）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mFNkFPwX5Rw7",
    "outputId": "c25c33bd-f796-479f-9c5d-b4849583560b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6647, grad_fn=<DivBackward0>)\n",
      "tensor(0.7841, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# コサイン類似度を求める\n",
    "cos = torch.nn.CosineSimilarity(dim=0)\n",
    "cos_sim_12 = cos(word_vec1, word_vec2)\n",
    "cos_sim_13 = cos(word_vec1, word_vec3)\n",
    "\n",
    "print(cos_sim_12)\n",
    "print(cos_sim_13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tRGDDBVyQQRD"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "1_Japanese_BERT_on_Google_Colaboratory.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "03eb68c6ddbd44a5b8f5b0619621aea6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "0877a5daaf5d4ce0af3a0243aba75e85": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_6f060378942046a9b6efae929d2437a0",
       "style": "IPY_MODEL_e2f5706766a14c60857eae166cd3741d",
       "value": " 110/110 [00:00&lt;00:00, 2.39kB/s]"
      }
     },
     "0bae21c8b02949459c0ba7c2c6f1b9eb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "11e85e8ec7d94fd5b8de08d2961ef755": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "139c75855f9f4269943ac8ef6e48e176": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "16f729cc483d478097f4c2f06fdd980a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "1e10d068eb9c45d5bb0f4f785bf15260": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "1ffcb2e7683e4f99aaf97b1101d674e1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "20fd2d8c04b74f439996d20bae2b794f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "23ea00ea53e24da19d64ab338bd57c98": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_cdab068e38da4bb1912e54a21d51365e",
       "style": "IPY_MODEL_d56aca463f264c3a87350f2e801c6451",
       "value": "Downloading: 100%"
      }
     },
     "2f4d368c90564f1d8d373a173237b290": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "30e2cbd19cd9471bb9b9686a47d98048": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "36533c7d595d47c2b6d4c0c1c15b40e9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "37894c08a57f45ed96b46378dcb180e6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_23ea00ea53e24da19d64ab338bd57c98",
        "IPY_MODEL_e8c4afa528b24faea2fdc16233f8be6d",
        "IPY_MODEL_0877a5daaf5d4ce0af3a0243aba75e85"
       ],
       "layout": "IPY_MODEL_f221281a596547babed013e6ff7bd187"
      }
     },
     "3a00a7c391b9467a8cb6a9c8753f83dd": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "3b5f12eace1b483fa3ed8536abe9c0de": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "47bd8f1f840d4ca29a2e44097c87aeef": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_fb23134d6b2847548cc7d2cab9f19944",
       "style": "IPY_MODEL_c01b3e87b9b547f08290d53143ba5b8a",
       "value": " 479/479 [00:00&lt;00:00, 10.3kB/s]"
      }
     },
     "47e5b240f277459c8cfd1b3a35f1f764": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_739de762d97e4d4bae2aa1fc08c8532e",
       "style": "IPY_MODEL_d735fb98a6904203832859217d993bd7",
       "value": "Downloading: 100%"
      }
     },
     "4f629491a0184baaa8cc91cae59a277e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_3b5f12eace1b483fa3ed8536abe9c0de",
       "max": 445021143,
       "style": "IPY_MODEL_0bae21c8b02949459c0ba7c2c6f1b9eb",
       "value": 445021143
      }
     },
     "6f060378942046a9b6efae929d2437a0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "739de762d97e4d4bae2aa1fc08c8532e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "76ebedcaaf7b4fdda29507fd92032cd1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "7a75bacaea254637beec23d3e385ca9e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_03eb68c6ddbd44a5b8f5b0619621aea6",
       "style": "IPY_MODEL_855885e49e2447bc9a431ccd35c5ff42",
       "value": "Downloading: 100%"
      }
     },
     "80acb35dd743411a9bc770708a9d2efd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_7a75bacaea254637beec23d3e385ca9e",
        "IPY_MODEL_b787c2057a85490d9d965c95ca43d083",
        "IPY_MODEL_8d2a5ece295e449fb0bba71d2aee285c"
       ],
       "layout": "IPY_MODEL_93d609b39966490ead20ba15642645e9"
      }
     },
     "855885e49e2447bc9a431ccd35c5ff42": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "88dd2af43a6444c5af84a7c5aa5b50b2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "8d2a5ece295e449fb0bba71d2aee285c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_88dd2af43a6444c5af84a7c5aa5b50b2",
       "style": "IPY_MODEL_c1b0f69d6d314e56959a57b1786cbb8a",
       "value": " 258k/258k [00:02&lt;00:00, 126kB/s]"
      }
     },
     "93d609b39966490ead20ba15642645e9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "a26dc6de226e49d69701bdff8dbb90d2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_76ebedcaaf7b4fdda29507fd92032cd1",
       "style": "IPY_MODEL_16f729cc483d478097f4c2f06fdd980a",
       "value": " 445M/445M [15:28&lt;00:00, 313kB/s]"
      }
     },
     "a9af140d784a440aa73c6739595389b0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_11e85e8ec7d94fd5b8de08d2961ef755",
       "style": "IPY_MODEL_1ffcb2e7683e4f99aaf97b1101d674e1",
       "value": "Downloading: 100%"
      }
     },
     "ae2cad25899449a4bf14a51e7a068362": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_a9af140d784a440aa73c6739595389b0",
        "IPY_MODEL_4f629491a0184baaa8cc91cae59a277e",
        "IPY_MODEL_a26dc6de226e49d69701bdff8dbb90d2"
       ],
       "layout": "IPY_MODEL_2f4d368c90564f1d8d373a173237b290"
      }
     },
     "b787c2057a85490d9d965c95ca43d083": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_36533c7d595d47c2b6d4c0c1c15b40e9",
       "max": 257706,
       "style": "IPY_MODEL_1e10d068eb9c45d5bb0f4f785bf15260",
       "value": 257706
      }
     },
     "c01b3e87b9b547f08290d53143ba5b8a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "c1b0f69d6d314e56959a57b1786cbb8a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "c33d1226f9d942a88e846d081d8c0e13": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_30e2cbd19cd9471bb9b9686a47d98048",
       "max": 479,
       "style": "IPY_MODEL_20fd2d8c04b74f439996d20bae2b794f",
       "value": 479
      }
     },
     "cdab068e38da4bb1912e54a21d51365e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "d56aca463f264c3a87350f2e801c6451": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "d735fb98a6904203832859217d993bd7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "e1e2996b1f564135882cc83f5ad05f7a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "e2f5706766a14c60857eae166cd3741d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "e8c4afa528b24faea2fdc16233f8be6d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_3a00a7c391b9467a8cb6a9c8753f83dd",
       "max": 110,
       "style": "IPY_MODEL_e1e2996b1f564135882cc83f5ad05f7a",
       "value": 110
      }
     },
     "f221281a596547babed013e6ff7bd187": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "f93a74551b4c4901bdc9d682b1116e80": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_47e5b240f277459c8cfd1b3a35f1f764",
        "IPY_MODEL_c33d1226f9d942a88e846d081d8c0e13",
        "IPY_MODEL_47bd8f1f840d4ca29a2e44097c87aeef"
       ],
       "layout": "IPY_MODEL_139c75855f9f4269943ac8ef6e48e176"
      }
     },
     "fb23134d6b2847548cc7d2cab9f19944": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

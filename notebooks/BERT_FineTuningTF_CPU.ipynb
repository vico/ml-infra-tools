{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c18f806e-6c8a-46dd-ad9f-23effdd97370",
   "metadata": {},
   "source": [
    "## 日本語BERTでlivedoorニュースを教師あり学習で分類"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8c2504-c489-4eb2-b46f-5d1c02a78946",
   "metadata": {},
   "source": [
    "参考情報：\n",
    "- https://nikkie-ftnext.hatenablog.com/entry/livedoor-news-with-tf-data-my-issues\n",
    "- https://qiita.com/sugulu_Ogawa_ISID/items/697bd03499c1de9cf082"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b21ddb42-2084-42d5-8c82-06423a414f25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fugashi                  1.1.0\n",
      "ipadic                   1.0.0\n",
      "tensorflow               2.5.0\n",
      "tensorflow-addons        0.13.0\n",
      "tensorflow-datasets      4.3.0\n",
      "tensorflow-estimator     2.5.0\n",
      "tensorflow-gpu           2.5.0\n",
      "tensorflow-hub           0.12.0\n",
      "tensorflow-metadata      1.1.0\n",
      "tensorflow-text          2.5.0\n",
      "transformers             4.8.1\n"
     ]
    }
   ],
   "source": [
    "# !pip install transformers fugashi[unidic-lite] ipadic\n",
    "!pip list | grep 'transformers\\|fugashi\\|ipadic\\|tensorflow'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "333b90a0-46d4-466f-bc7c-9ee0d7993432",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A dependency of the preprocessing for BERT inputs\n",
    "# !pip install -U tensorflow-text\n",
    "# !pip install -U tensorflow_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c42b692b-f1bf-4be3-9f77-7168991b2c10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU found\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "\n",
    "if tf.test.gpu_device_name():\n",
    "    print('GPU found')\n",
    "else:\n",
    "    print(\"No GPU found\")\n",
    "\n",
    "import collections\n",
    "import pathlib\n",
    "import re\n",
    "import string\n",
    "\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras import preprocessing\n",
    "from tensorflow.keras import utils\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_text as tf_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e8a1108-f36f-43b4-b21c-659f20f00d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "447c205f-f6d2-441c-9793-d7949b4f1046",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.rondhuit.com/download/ldcc-20140209.tar.gz'\n",
    "\n",
    "dataset_dir = tf.keras.utils.get_file('ldcc-20140209.tar.gz', url,\n",
    "                                  untar=True, \n",
    "                                  cache_dir='.',\n",
    "                                  cache_subdir='data/livedoor')\n",
    "dataset_dir = pathlib.Path(dataset_dir).parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "654a12a8-958d-4d2e-9b3a-3a8a443711c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('data/livedoor/text'),\n",
       " PosixPath('data/livedoor/ldcc-20140209.tar.gz.tar.gz')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(dataset_dir.iterdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23a63dde-6333-483f-92d4-ee3a3cd2d4a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('data/livedoor/text/sports-watch'),\n",
       " PosixPath('data/livedoor/text/README.txt'),\n",
       " PosixPath('data/livedoor/text/peachy'),\n",
       " PosixPath('data/livedoor/text/movie-enter'),\n",
       " PosixPath('data/livedoor/text/dokujo-tsushin'),\n",
       " PosixPath('data/livedoor/text/CHANGES.txt'),\n",
       " PosixPath('data/livedoor/text/livedoor-homme'),\n",
       " PosixPath('data/livedoor/text/topic-news'),\n",
       " PosixPath('data/livedoor/text/it-life-hack'),\n",
       " PosixPath('data/livedoor/text/kaden-channel'),\n",
       " PosixPath('data/livedoor/text/smax')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# フォルダのファイルとディレクトリを確認\n",
    "text_dir = dataset_dir/'text'\n",
    "list(text_dir.iterdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f228a4a-ca9c-4b82-a45e-c58503a744b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "カテゴリー数: 9\n",
      "['sports-watch', 'peachy', 'movie-enter', 'dokujo-tsushin', 'livedoor-homme', 'topic-news', 'it-life-hack', 'kaden-channel', 'smax']\n"
     ]
    }
   ],
   "source": [
    "# カテゴリーのフォルダのみを抽出\n",
    "categories = [name.stem for name in text_dir.iterdir() if name.is_dir()]\n",
    "print(\"カテゴリー数:\", len(categories))\n",
    "print(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64264bbf-9730-433a-b807-7fc9d5a47831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0： http://news.livedoor.com/article/detail/6255260/\n",
      "\n",
      "1： 2012-02-07T09:00:00+0900\n",
      "\n",
      "2： 新しいヴァンパイアが誕生！　ジョニデ主演『ダーク・シャドウ』の公開日が決定\n",
      "\n",
      "3： 　こんなヴァンパイアは見たことがない！　ジョニー・デップとティム・バートン監督がタッグを組んだ映画『ダーク・シャドウズ（原題）』の邦題が『ダーク・シャドウ』に決定。日本公開日が5月19日に決まった。さらに、ジョニー・デップ演じるヴァンパイアの写真が公開された。\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ファイルの中身を確認してみる\n",
    "file_name = text_dir/\"movie-enter/movie-enter-6255260.txt\"\n",
    "\n",
    "with open(file_name, encoding='utf-8') as text_file:\n",
    "    text = text_file.readlines()\n",
    "    print(\"0：\", text[0])  # URL情報\n",
    "    print(\"1：\", text[1])  # タイムスタンプ\n",
    "    print(\"2：\", text[2])  # タイトル\n",
    "    print(\"3：\", text[3])  # 本文\n",
    "\n",
    "    # 今回は4要素目には本文は伸びていないが、4要素目以降に本文がある場合もある\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e1cff13-7e42-4351-a742-850835b218d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification\n",
    "\n",
    "checkpoint = \"cl-tohoku/bert-base-japanese-whole-word-masking\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a70bc87-23b6-4602-83f2-cd0867210af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def labeler(example, index):\n",
    "    return example, tf.cast(index, tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "827a715d-8e1f-4f50-aa36-529c9666e1c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: sports-watch\n",
      "1: peachy\n",
      "2: movie-enter\n",
      "3: dokujo-tsushin\n",
      "4: livedoor-homme\n",
      "5: topic-news\n",
      "6: it-life-hack\n",
      "7: kaden-channel\n",
      "8: smax\n"
     ]
    }
   ],
   "source": [
    "text_datasets = []\n",
    "label_count = 0\n",
    "\n",
    "# text_dir = os.path.join(os.getcwd(), \"text\")\n",
    "for data_dir in text_dir.iterdir():\n",
    "    if data_dir.is_dir():\n",
    "        print(f\"{label_count}: {data_dir.stem}\")\n",
    "        text_file_names = data_dir.glob('*.txt')\n",
    "\n",
    "        text_tensors = []\n",
    "        for text_file in text_file_names:\n",
    "            lines_dataset = tf.data.TextLineDataset(text_file)\n",
    "            # 1行1行がTensorとなるので、ファイルの文章全体をつないでTensorとする\n",
    "            sentences = [\n",
    "                line_tensor.numpy().decode(\"utf-8\") for line_tensor in lines_dataset.skip(3)\n",
    "            ]\n",
    "            concatenated_sentences = \" \".join(sentences)\n",
    "            # subdirのファイルごとにTensorを作り、Datasetとする\n",
    "            text_tensor = tf.convert_to_tensor(concatenated_sentences)\n",
    "            text_tensors.append(text_tensor)\n",
    "        text_dataset = tf.data.Dataset.from_tensor_slices(text_tensors)\n",
    "        text_dataset = text_dataset.map(lambda ex: labeler(ex, label_count))\n",
    "        text_datasets.append(text_dataset)\n",
    "        label_count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de50316-b6fe-45db-ad13-f3b356d7b9e5",
   "metadata": {},
   "source": [
    "## 準備2：LivedoorニュースをBERT用のDataLoaderにする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b316b3b9-bd0f-46cd-8048-560dfd66a41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_tokenizer():\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "\n",
    "    def _tokenizer(text_tensor, label):\n",
    "        text_str = text_tensor.numpy().decode(\"utf-8\")\n",
    "        tokenized_text = tokenizer(text_str, padding=True, truncation=True, return_tensors=\"tf\")\n",
    "        return tokenized_text.input_ids[0], label\n",
    "\n",
    "    return _tokenizer\n",
    "\n",
    "def tokenize_map_fn(tokenizer):\n",
    "    \n",
    "    def _tokenize_map_fn(text_tensor, label):\n",
    "        encoded_text, label =  tf.py_function(\n",
    "            tokenizer, inp=[text_tensor, label], Tout=(tf.int32, tf.int32)\n",
    "        )\n",
    "        encoded_text.set_shape([None])\n",
    "        label.set_shape([])\n",
    "        return encoded_text, label\n",
    "\n",
    "    return _tokenize_map_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bdd6464a-ec56-4d9f-b62e-afb0ec084f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "tf.random.set_seed(1234)\n",
    "\n",
    "BUFFER_SIZE = 2000\n",
    "BATCH_SIZE = 16\n",
    "TAKE_SIZE = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b826fa78-977a-4f17-b967-f6ce883a4384",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ShuffleDataset shapes: ((), ()), types: (tf.string, tf.int32)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_labeled_data = text_datasets[0]\n",
    "for labeled_data in text_datasets[1:]:\n",
    "    all_labeled_data = all_labeled_data.concatenate(labeled_data)\n",
    "\n",
    "all_labeled_data = all_labeled_data.shuffle(\n",
    "    BUFFER_SIZE, seed=RANDOM_SEED, reshuffle_each_iteration=False\n",
    ")\n",
    "all_labeled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "09dd8de4-454b-470c-a564-9336d8ccb763",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tokenized_data = all_labeled_data.map(tokenize_map_fn(my_tokenizer()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "499ee918-9476-4900-9ec2-d98a3a5a2773",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([None]), TensorShape([]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_shapes = tf.compat.v1.data.get_output_shapes(all_tokenized_data)\n",
    "output_shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a6d9458b-18f3-43e7-9a40-02219501a332",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = all_tokenized_data.take(TAKE_SIZE)\n",
    "test_data = test_data.padded_batch(BATCH_SIZE, output_shapes)\n",
    "train_data = all_tokenized_data.skip(TAKE_SIZE).shuffle(\n",
    "    BUFFER_SIZE, seed=RANDOM_SEED\n",
    ")\n",
    "\n",
    "val_data = train_data.take(TAKE_SIZE)\n",
    "val_data = val_data.padded_batch(BATCH_SIZE, output_shapes)\n",
    "train_data = train_data.skip(TAKE_SIZE).shuffle(BUFFER_SIZE, seed=RANDOM_SEED)\n",
    "\n",
    "train_data = train_data.padded_batch(BATCH_SIZE, output_shapes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c84760a2-b2bc-421c-8228-ba95152c19ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TFAutoModelForSequenceClassification\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.optimizers.schedules import PolynomialDecay\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1f571788-a6bd-494f-930f-364a318573c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 3\n",
    "# The number of training steps is the number of samples in the dataset, divided by the batch size then multiplied\n",
    "# by the total number of epochs\n",
    "num_train_steps = 222 * num_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "173fec05-a308-4bb8-9136-f0f070e1d75f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at cl-tohoku/bert-base-japanese-whole-word-masking and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f0ab9489be0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f0ab9489be0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:From /home/vjai/.local/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py:5043: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "443/443 [==============================] - ETA: 0s - loss: 0.4827 - accuracy: 0.8585 WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "443/443 [==============================] - 5042s 11s/step - loss: 0.4827 - accuracy: 0.8585 - val_loss: 0.1434 - val_accuracy: 0.9600\n",
      "Epoch 2/3\n",
      "443/443 [==============================] - 5013s 11s/step - loss: 0.1350 - accuracy: 0.9641 - val_loss: 0.1161 - val_accuracy: 0.9600\n",
      "Epoch 3/3\n",
      "443/443 [==============================] - 5029s 11s/step - loss: 0.1128 - accuracy: 0.9696 - val_loss: 0.1029 - val_accuracy: 0.9667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f089c7f90d0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model = TFAutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=9)\n",
    "lr_scheduler = PolynomialDecay(\n",
    "    initial_learning_rate=5e-5,\n",
    "    end_learning_rate=0.,\n",
    "    decay_steps=num_train_steps\n",
    "    )\n",
    "opt = Adam(learning_rate=lr_scheduler)\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "model.compile(optimizer=opt, loss=loss, metrics=['accuracy'])\n",
    "# model.compile(optimizer=opt, loss=loss, metrics=['accuracy', F1_metric()])\n",
    "model.fit(\n",
    "    train_data,\n",
    "    validation_data=val_data,\n",
    "    epochs=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18639129-d304-4880-b228-f2d016fdd761",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a586948-aa9e-45e9-9462-e13ea6afb3fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7f40f7-cd13-40cc-8cd7-8fd7a734fae6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3710b60-95e0-4c00-aa43-9b211c1bcf60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6a5032-514f-494b-bd6e-3bdbc46ec78d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
